<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="record the ML metrics"><title>Metrics</title>
<link rel=canonical href=https://xzxg001.github.io/p/metrics/><link rel=stylesheet href=/scss/style.min.663803bebe609202d5b39d848f2d7c2dc8b598a2d879efa079fa88893d29c49c.css><meta property='og:title' content="Metrics"><meta property='og:description' content="record the ML metrics"><meta property='og:url' content='https://xzxg001.github.io/p/metrics/'><meta property='og:site_name' content='xzxg001'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='model evalution'><meta property='article:tag' content='metrics'><meta property='article:tag' content='machine learning'><meta property='article:published_time' content='2024-04-04T00:00:00+00:00'><meta property='article:modified_time' content='2024-04-04T00:00:00+00:00'><meta property='og:image' content='https://xzxg001.github.io/p/metrics/image.png'><meta name=twitter:title content="Metrics"><meta name=twitter:description content="record the ML metrics"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://xzxg001.github.io/p/metrics/image.png'><link rel="shortcut icon" href=/favicon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu_ef0b97d427b7260a.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🍥</span></figure><div class=site-meta><h1 class=site-name><a href=/>xzxg001</a></h1><h2 class=site-description>show my ideas and practices.</h2></div></header><ol class=menu-social><li><a href=https://blog.csdn.net/xzxg001 target=_blank title=xzxg001 rel=me><!doctype html><svg id="Layer_1" xmlns:xlink="http://www.w3.org/1999/xlink" width="143" height="54" viewBox="0 0 143 54" enable-background="new 0 0 143 54"><image id="image0" width="143" height="54" x="0" y="0" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAI8AAAA2CAYAAAD+psouAAAAIGNIUk0AAHomAACAhAAA+gAAAIDo AAB1MAAA6mAAADqYAAAXcJy6UTwAAAAGYktHRAD/AP8A/6C9p5MAAAAJcEhZcwAAFiUAABYlAUlS JPAAABWmSURBVHja7Zx5dFzVfcc/982uWbRrLMmyZEm2vG8CI1s2Fth4j9lXG0ho0qanIYG2ado0 TXpOe5KShrRJ4ARISAmLIQGMMQRsg8HYGOPdsq3FizZrtXaNZp+39I+xRxrJxsPIhqZnPn+9p3nv vt+793vv/d3f7z4JTdM0EiSIA+nLNiDBny8J8SSIm4R4EsRNQjwJ4iYhngRxkxBPgrhJiCdB3CTE kyBuvjDxaKpKV30dVdu3EvC4CXo9yMHAl/3+CcaA/ot4iKYqVG55k51PP0Hu9JkIAfWf7qX09rvI njb9y66DBHHyhYin5fgxdj7zJK5z55ADQRoPHUSSJKavXP1lv3+CMSCuVm4r6PUy2NXJ6V07ObJ5 E92N9Yx8lMlqJb/0WkoqllJ4XRn2LCeSTvdl10mCGLkq4mk5VsnRLW9Q+8H7ePv7Lm+EJJExsZBp S5czc9Va0vLzv+x6SRADV1Q8SijEJ79/lgN/eBlvfx+qonyu+yWdjvSCiSz/23+gqGwhCPFl10+C z+CKicfnGmDXM7/m4KuvoIRCYyrL4nCw/O++x8xVa5H0X4hbliAOroh4gl4P2x5/jMotmz/3aHMp DGYzNz78KKW33YneZPqy6ynBRRhzt5aDQbb97D+ofOtNAHKmTKZw6kRsNhOKquH1BGhtaKel9hRy IDquY01NJX96CZnZqVjMBlRNo7fbzZmjNQycO8dHTz2JKcnK7K/cjJCuQEiqrRFqjqB1tYMAkZkN M+ZDZk7MU6Qsy1RXV1FdVUVPTzcGg4Gi4knMmTOH9PSMmMpQVZXm5mbOnD5FW1srPp8POSSTkprC hPwC5syZg81mH9Or9vb0UFV1gs7OToQQpKalMW3aNJzOcWOvx/OMaeTRVJWjW95g2+OPkZqRzJKv LGLCeCvSRdrBG5DY/UEV1XsPYzAZWbB6CTNnOjHqRz8+pAhOnOhk7zsfYUnL4s6f/YKMgonxGen3 otVVo732G7TawzBiZBR6PcxdjHTHNyCvCPSGixbj8/k4dOggv3v2N9TX1Y1aOVqtVpbdtJx779uA 0+lEuojYe3p6eGXjS+zY8R49PT2XNNloNLJo8fXcedfdTJ48Gf0lbFJVlbbWVlpampmQn096egaN DQ288Pxz7Nv3KcFgMOp6SZKYM2cuD371IabPmI7BYIy36cN1Nxbx9Le28Op3HyXZruOG1aXYkwSK Ch19Ady+ABaTgew0C4bzq++QrHKispXUzBQKJgz1LE9Qo6PHg6pqpNrNpNkNSAJa2728/8Zu0ifN 5NYf/xTd5/V/utrQNj+HtvsdNL/3s69NTkO679uI61eDLvo53V1dPP/8c/zp7beQZXmo8oQYJaK8 vAl846++yaJFi9ENCztomsYf//AKzzz966gyPou0tHRuufU27r1vPUbj6Iaura3hRz/8AR3t7RQX T2JheTmb39iEy+X6zHKTLBbu3XA/d955NxaLJd7mH9u0dWTzJiQtwJLlZdiTBG29fl54eRvNZ9uR FRWdJHCOy+C+e1ZQlOPAoJeYPTcvMkMoGuw51sabr72D1xfuJWazkQXlpaxbNpuccRYWLp/P1j/s 4MzHH1FSsTR241x9aL97DPXIHlDV8N/yJyNdvwaycmBwAI5+gnpoFygyDPSi7diEmFsOKemRYgKB AK/+8Q8R4ej1esrKFrBm7ToyszJxDbjYufMDtm19l0AgQHPzWZ79zdNMmTIVp9MZKUdRFLq6OiPC yc8voOKGGykpKSEjMxMhBN1dXRw8eIBtW9/F7XbT29vDC88/R3d3F488+rfoRoj64IEDdLS3A1Bf X8fZs00Eg8FwAHbGDG6ouJGc3Fy8Xi/HKit5//3tuN1uvD4fL7/0IllZTlasWImIc1Ubu3g0Fc0/ iNpehdLXgqJJHN70RxbeOItkh5H6ln6e/v27FObnsObrS9DLPoSQONF4jiefep2HHljNzGInF0bz oKzy2rsHObD3KLfespIsuxENcIcE72zbRV1TJ48+dBPFRamMG+9k72+foMDWjaQ3oXNOQmQUIQwm 4CIvLofQXn0a9dDu8LnVgXTr1xCr7gHDMOd76a3ojuxBff7naG2N4RFnRHHnOjrYvn0rsixjNBp5 8KsPcfc992IwDE0l80pLuXb+dfzyv39OV1cXHR0dBPz+aJNkGbfbDYAQEitWrGT9/Q9EXTN5cgkL yxexfv39PP74T9n36aeEQiE+2LGD0tJrWFJxQ1RDd3V1Ro5VVSUYDJKcnMLX//IvWb16LfphI/XS ZTdx7/oNPPaTf+fo0aN4vV52friD8vJF2O3x+VexeaGainLuFMEjrxOq+wS19ywNldVIqOQWjsft 19j4xm7mzZxEnjONU639vLe3ilMNrUzPMrPq+lJefu0jul1DS/hjp8/R1NjB/bfeSIpB5lS7i/f3 1VJzso6l5XMQQT+vvLUfWYVpC2bT33GOnsYGlK4zBKu2IVe9g+btv7i9u99Bfe/18LHBhLT+YcSa DdHCCbcizFuE9MhPkFbeg1izHmwpUZfU1Z2ht7cXgIyMDFatWh0lnHAxgsWLr+dbDz9CQcFEKipu JCU1NeoaRZHxeDxhkwx6bA7HJas7PSODv//uPzKvtBQAt3uQ7du2RsR3gQt2XSA1LY2//+73WLfu lijhXGDcuHHct+EBbOfFcub0aQYHB+MSTszi0XwDKHW70Ty9gEDTbHy6dS96vcDhMLL3eDOdzc04 M1LoNaQx5+YNVNXWc7yxF4/BQV6aifRkK59UNkXK3HOwjsl5mZhFiKoOPxOX3kZb7yC79hymzy9Y ecN89u87SnOnm+xsBx6Xh/qqNtBMYTF31SPX7gBGuGwDvahvvwRq2DGWlt2GuOEW+Ky0R0EJ4v5H ENcsGXVdMDgkeI/HS0NDAxdzE4UQLKmo4D8f/znf+vZ3RvXmUGho5NHr9dis1s+s89TUVNauXRdZ dVVWVtI/Ilo/XDySJLFixSoWLFz4meVOnDgx8uze3l6CY9jZENO0pTTsQ/UOABKhBoG7pQ13twvJ BJIEtTX15E3IpfH0GfZVt3Bo9y48gy4Mgx4aW7qYlqnnmnkz2PLuTgw6HQioq6pm4e3LkCSZHdu2 cvDQcbrbW3FYbfS0dZFnlbHZ7Zzr7CUzxY4iy/TVdeP2JZE0Lw8p1Y/S04iuvQYpe1rEVq1yL1pX W7hB052w6p7PFs4FLrHyKJlSgsPhwOVyMTDQz49+9ANWrFjJ8hWryMzMxG63R5xZIQRZWc6LliPL Mp7h4rnMUlwIwcxZs0hJScHtHsTtHuTokSPk5U0YEk9Pd+Q4y+lkzdq1o0bFi9mhnhe/ECJufyd2 8fQ0AqB6LQSqanEZdIQUGb2ix+dXUWQFi9lEdo6TIsVK5+kzFGfnIZnMZGelgOZGMpoIBoK0nT2L hgaShKTXoykBZs6ZSV/nAPokO9m5eVhsFvQ6CavVgqqq9PWHe8dgMEAw4Ec63kxSeS7oAqg9DUPi kUPQeBICvvD5tFJITou7cgCys3O4/Y67eHnji/j9ftyDg7z+2qu8teVNCguLmFxSwrRp05kzd94l l+gAiizjdoenCL3egM1mu+yz09LSGT9+PC0tzQA0NjZG/d7f3x85Li29NkpYl8Lj8UacdqvVdtHp LVZiu1MJN54WEKBpeLxeFEUl5PXTdraTwkkT2fnu+yxbMJ2QwYqrtw9zUhLTZxWTKnyYktOp2neS 8oqF3L5sGhrwX4MKPe4ANoeR8ukT2OE5RVBOwauFKM5Pw2A20Hmuk8yMVKoO1gLg9ftQFBUtpKDJ AqEDLTRs2PV50ZrrQNNAp0NMKEaYk+KuHACTycQ9995HUXExv3/ufzh96iQAwWCQ2toaamtr2L5t K+npGSypqOC+9Ruw20f7M7Ii4z7v8+j1emz2y4sHICcnJ3Lc1Xkucuz3+fD5fJHzZTfdFNMo4nYP opwXj81mRa+7yuIRSelorg50yTJSkhnfuX5kOYQcCnGmppmyZfPY/YGF2vp2SnIcTF45G4RA8XnR Gy0MyBJ1dY08sroMgy78gtfOm8SJ42fIXzgDu+bi5oWTkCxWVK8LWfayY28zRcX52M0WGqtOhyvM 60VRFaQUCxjDvoiwDUV1tVAABs77AUYzZGRfkeSq2Wxm8eLrKSsrY//+fbz33nZO1tTgcrnwer34 /X5aW1vY+NKLfPjBDr7z6N8xf/51UXGeUGj4tKWLOYJsMpsjx8PF0tvbG/G9hBBMnTotpvK8Hs/Q yGOzff7Y2TBicph1eXPDy1jJj7ksF1OOIzI811fV01Tbyj13LafyTCtH6joJCiOS2YqUnEGzV7B9 5wHWrrme3NSh+bhsejZmk54d+6tx6R3oHGmg0+NSDOw5cZY+b4A71lVwaNcxPK5wj9UZ9ZiK0zDP zkQIBWGyocudMWSookSmLKHTg2Vso85IDAYj5eWL+dd//TeeePIpvv/PP2T9hgeYPWduxO9pb2/n 5z/7KYcPHYy6d3DQFWk0vSG2aSt839BqyD5shdbbN+Qs2+32mIN97uHi+SKmLSmrGH1fE3JbNZI1 RMqkdAx7DAQDAQIeLx//6WOuWV7ObesqeG3LTvYerkEnSaiaRkpGBrd9ZREziqLzPhaTgftuLmPn obO8+MrbCE1FU1UQEqXzZ7FhzWwqP67m5OGaSLLVnu7AUmRD6AMg6TBMWoJIGuHTnO+NmqZd1Q3a 6RkZlC9axIKFC3ENDLB//z5+9atf4BoYoLOzk1/98r957vmXIp2su3vIubUmWS8aMR6Jpmm0NDdH zh3DxdMzJJ6MzKyY7fa43RHx2KzWqy8eoTehK1mKZrCgdpwk1WnGYBp6+VAgwKdvf4hzYj7fXL8a RS/oHQxgtxopSDejodHU7Cbgl5lUnIIsq9Se7GN8rp21i4tZVlZEQ6cPRVYZl55ES30PW555C9+I GIQj3YHBakOyWNEXliFlTY6202BAs56fDuQQ2mA/V3tHkCRJpKSmsnzFSmRF5rGf/BiApqYmqk4c Z+as2QD0dHdF7rkQUb4c7e3tdJzrCL+bEEydOrTfu2/YyJOZEVtCFsDj8aCc74xW29hGnpg7p9Cb MEy+AePc27HNXIrRFu0UappGR30jnR0DjE8zMivfzsQME0Jo+IPwwaYP+Wjzh7g8Kmfbg2zf+DZV h0+hamA2CKbmJjEj34bdCGdPNY4SjpAkbLnFmGasxDD3NiTnFBAjzL/g5wAE/NB0OrwCi5MTx4/x xqbXIymAyzF37ryo846OjshxT/dQIjQjhuy7qqrs3/cp/X3h2I7D4WDqtKmR33uHJVYzYhSPpml4 vR7U8+kam9WGfgzbfj/3yC7smRhzp1BYXjHqt6TkZPJyRwe/zEZYeusSlt6xFIdVoiDXzMr7v8LM ayaPysAbjRLjclJGbQIzWW3kzFuAPqsIYb5EdNaShJg4JRx8QkM9tAutt5OYCAXhZCX4wgnUpsZG Hv/Zf/LkE79i48YXo5zVS9E7IlM+3A8ZPm1lZF6+sdvaWtn8xib859Mcs2bPJi1tKOc2fOTJyMyM 6RXDsSbPUHtZk66+wzwSIQQL1j+AJTkl6u/JmekYzaPncklAQb6D4kIHOgkMepg5LY3UlNHXCiDN mYFxxAawzMIiCq6dfxnDJMS8xeHgIED7WbSn/g262sLJz4sRCkJXG+rj30X5l6+hPvlD0DTa2lrp 6uokFAry9ltb2PjSC/T09ER67Ujcbjevv/5q5NxgMDJj5qzIeU/vkLDSMy7e2Jqm4fP5qKmp4vv/ 9D0aGuoBsNns3LR8ZZST3TPM57lUeSORZRm3J7zi0+l0WG22qx8kvBh2p5OKb/4N7/3iceTzvcNs MUYtT+PFZDEh6YZ0bXE4WPrwdzDHsrzNL0asvBc2/hJNkdFO7Ef98cOI+TcgJk5BS04HgwERDKB1 d0BDLeqRj6HtfOrk0EcQClBUVExe3gSqq6tQFIUXnv89Bw7sZ+HCcgoLi0hOSUGSJELBIC0tLRw4 sJ89H++OmLFo0WJSUlIi58N9nv7eXlpbWzAaTaiqgt/vp7Ozk5bmZmqqq/jkkz2RVZZOp2PdLbdw 3XVlUa8Zj88zKsptjW3FdynGtCVj1tqbaauu4tiftqCp6vks05X9GENnMHDTo/9A3pzS2G4QEmLl XRDwoW36bdhxbm1Ae7MJYU5CMxgRkhS2N+AP+0ba0GgiSmaDwURmVhb//C8/5Aff/ycaGsKfDdVU V3Pq5EksFgsGozG8n0dV8fl8BAKBSNxl3Lhx3P/gg1FmDZ+2XnzxeTZv3oQk6VBVFVVV8Qf8+H2+ qA1cer2erz70F9x5592Yh8V7hmfoIfZpS5GjA5XWy+TXLseYxGOyWln68CN4+nqo/3QvHpcHOSSD +SKjj6xD7tajDoQQeh26NAmRHERIo8XmcblRZBmTzUbZhgeZsXL159uGajAibv0aUlom2lsvhHNd wQCaN1zhI58o9HqwpyBmL0Cs/w4IgQDGj8/jiSd/zTPPPMUnn+yhv6+PUCg0Krt9AaPRSE5OLn/1 zb+msLAo6jen04nf7480/KXKkCSJpCQr2dnZ3P/gV0dtKoNwsPDCislstmAxxxbjkWUZr3dIPMnJ yWNp/iuzAd7b18fB117h+Dtvs3TNPAryRxulDlrx729E9YYdT70zDdOcdIQxOqurKBq73q+irSvA NXfczdSlyzEmjSHY19WOVrkXzp5Gaz8LXjcEA2A0gcUK6U5EbgFi6jwoKLloglSWZRoa6jl65DBN TU10dXbS09uDHJLRG8I9ODs7h8klJVx3XRm5ueNHldHQUM/BAwdoa2ulu7sb18AAXq8XWQ6h1xsw WyykpaUxfvx4SkqmMmv27KhpL8qeUIjfPftbjh2rxDluHH/zrW+Tlnb5HJ7b7eZ3z/6WUydrKZky hQcf/BqOMQjoin16o8oy506f4tgbr7BwbjKGkXuTNQnNr6CFdCBUhBGEUYCIvq5nQKbJlcL0VetI Hndl0gtA2DH2+8KOs6qApAtn243msJBieI6maYRCIQJ+P4FgEE1TEUJCp9NhsZgxmcyXdUBDoRDB YIBgMISiKFFlGI1GzGZzTH6j3+/H5/NiMBhJSkq6ZEJ2pP1er5dgIIDFYsE8hi2ocBW+GNVUleot r5ClO0eSUUEX42wTksEdMuKyT6Gk4qbEB39/BlyVz43lYIDOmhPInXUofS1IWgijQWDQS+iksM+h KBAIyqjoUSQT+sxCDFkFjJuS+K8Zfy5ctX90ABDy+Qj5vKDKeHu68A+6CPk8CCFhtNmwpKRjciQj JD2GJCv6GPI9Cf7vcFXFk+D/N4l/K5cgbhLiSRA3CfEkiJuEeBLETUI8CeImIZ4EcZMQT4K4SYgn QdwkxJMgbhLiSRA3CfEkiJv/BcItCVyOzW5IAAAAJXRFWHRkYXRlOmNyZWF0ZQAyMDI1LTA0LTEy VDAzOjA3OjUyKzAwOjAwLhIaCgAAACV0RVh0ZGF0ZTptb2RpZnkAMjAyNS0wNC0xMlQwMzowNzo1 MiswMDowMF9PorYAAAAodEVYdGRhdGU6dGltZXN0YW1wADIwMjUtMDQtMTJUMDM6MDc6NTIrMDA6 MDAIWoNpAAAAAElFTkSuQmCC"/></svg></a></li><li><a href=https://github.com/xzxg001 target=_blank title=xzxg001 rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/about/><svg class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>About</span></a></li><li><a href=/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#性能指标的分类>性能指标的分类</a><ol><li><a href=#回归性能指标>回归性能指标</a><ol><li><a href=#平均绝对误差>平均绝对误差</a></li><li><a href=#平均偏差误差>平均偏差误差</a></li><li><a href=#相对绝对误差>相对绝对误差</a></li><li><a href=#平均绝对百分比误差>平均绝对百分比误差</a></li><li><a href=#均方误差>均方误差</a></li><li><a href=#均方根偏差>均方根偏差</a></li><li><a href=#相对平方误差>相对平方误差</a></li><li><a href=#归一化-rmse>归一化 RMSE</a></li></ol></li><li><a href=#分类性能指标>分类性能指标</a><ol><li><a href=#混淆矩阵>混淆矩阵</a></li><li><a href=#准确率>准确率</a></li><li><a href=#精确率查准率>精确率/查准率</a></li><li><a href=#召回率查全率敏感度>召回率/查全率/敏感度</a></li><li><a href=#特异性>特异性</a></li><li><a href=#fβ_><strong>Fβ_Score</strong></a></li><li><a href=#roc曲线和auc>ROC曲线和AUC</a></li></ol></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/metrics/><img src=/p/metrics/image_hu_8c83dcf5064230d1.png srcset="/p/metrics/image_hu_8c83dcf5064230d1.png 800w, /p/metrics/image_hu_9fc496c9a4e93825.png 1600w" width=800 height=800 loading=lazy alt="Featured image of post Metrics"></a></div><div class=article-details><header class=article-category><a href=/categories/machine-learning/>Machine Learning</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/metrics/>Metrics</a></h2><h3 class=article-subtitle>record the ML metrics</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Apr 04, 2024</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 10 分钟</time></div></footer></div></header><section class=article-content><h1 id=机器学习常用性能指标总结metrics><a href=#%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e5%b8%b8%e7%94%a8%e6%80%a7%e8%83%bd%e6%8c%87%e6%a0%87%e6%80%bb%e7%bb%93metrics class=header-anchor></a>机器学习常用性能指标总结metrics</h1><p>​ 在机器学习中，<a class=link href=Metrics>性能指标</a>是衡量一个模型好坏的关键，通过衡量模型输出y_predict 和 y_true之间的某种"距离"得出的。</p><p>​ 性能指标往往是我们做模型时的最终目标，如准确率，召回率，敏感度等等，但是性能指标常常因为不可微分，无法作为优化的loss函数，因此采用如cross-entropy, rmse等“距离”可微函数作为优化目标，以期待在loss函数降低的时候，能够<strong>提高性能指标</strong>。而最终目标的性能指标则作为模型训练过程中，作为验证集做决定(early stoping或model selection)的主要依据，与训练结束后评估本次训练出的模型好坏的重要标准。</p><h2 id=性能指标的分类><a href=#%e6%80%a7%e8%83%bd%e6%8c%87%e6%a0%87%e7%9a%84%e5%88%86%e7%b1%bb class=header-anchor></a>性能指标的分类</h2><p>​ 根据问题类型的不同，机器学习中的性能指标主要分为：回归性能指标和分类性能指标。</p><h3 id=回归性能指标><a href=#%e5%9b%9e%e5%bd%92%e6%80%a7%e8%83%bd%e6%8c%87%e6%a0%87 class=header-anchor></a>回归性能指标</h3><h4 id=平均绝对误差><a href=#%e5%b9%b3%e5%9d%87%e7%bb%9d%e5%af%b9%e8%af%af%e5%b7%ae class=header-anchor></a>平均绝对误差</h4><p>​ 平均绝对误差（Mean Absolute Error，MAE），也称为 L1 损失，是最简单的损失函数之一，也是一种易于理解的评估指标。它是通过取预测值和实际值之间的绝对差值并在整个数据集中取平均值来计算的。从数学上讲，它是绝对误差的算术平均值。MAE 仅测量误差的大小，不关心它们的方向。MAE越低，模型的准确性就越高。</p><p>优点：</p><ul><li>由于采用了绝对值，因此所有误差都以相同的比例加权。</li><li>如果训练数据有异常值，MAE 不会惩罚由<a class=link href="https://so.csdn.net/so/search?q=%e5%bc%82%e5%b8%b8%e5%80%bc&amp;spm=1001.2101.3001.7020" target=_blank rel=noopener>异常值</a>引起的高错误。</li><li>它提供了模型执行情况的平均度量。</li></ul><p>缺点：</p><ul><li>有时来自异常值的大错误最终被视为与低错误相同。</li><li>在零处不可微分。许多优化算法倾向于使用微分来找到评估指标中参数的最佳值。在 MAE 中计算梯度可能具有挑战性。</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>mean_absolute_error</span><span class=p>(</span><span class=n>true</span><span class=p>,</span> <span class=n>pred</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>abs_error</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>true</span> <span class=o>-</span> <span class=n>pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>sum_abs_error</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>abs_error</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>mae_loss</span> <span class=o>=</span> <span class=n>sum_abs_error</span> <span class=o>/</span> <span class=n>true</span><span class=o>.</span><span class=n>size</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>mae_loss</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=平均偏差误差><a href=#%e5%b9%b3%e5%9d%87%e5%81%8f%e5%b7%ae%e8%af%af%e5%b7%ae class=header-anchor></a>平均偏差误差</h4><p>平均偏差误差(Mean Bias Error ,MBE)是测量过程高估或低估参数值的趋势。偏差只有一个方向，可以是正的，也可以是负的。正偏差意味着数据的误差被高估，负偏差意味着误差被低估。平均偏差误差 是预测值与实际值之差的平均值。该评估指标量化了总体偏差并捕获了预测中的平均偏差。<strong>它几乎与 MAE 相似，唯一的区别是这里没有取绝对值。这个评估指标应该小心处理，因为正负误差可以相互抵消。</strong></p><p>优点：</p><ul><li>想检查模型的方向（即是否存在正偏差或负偏差）并纠正模型偏差，MBE 是一个很好的衡量标准。</li></ul><p>缺点：</p><ul><li>就幅度而言，这不是一个好的衡量标准，因为误差往往会相互补偿。</li><li>它的可靠性不高，因为有时高个体错误会产生低MBE。</li><li>作为一种评估指标，它在一个方向上可能始终是错误的。</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>mean_bias_error</span><span class=p>(</span><span class=n>true</span><span class=p>,</span> <span class=n>pred</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>bias_error</span> <span class=o>=</span> <span class=n>true</span> <span class=o>-</span> <span class=n>pred</span>
</span></span><span class=line><span class=cl>    <span class=n>mbe_loss</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>diff</span><span class=p>)</span> <span class=o>/</span> <span class=n>true</span><span class=o>.</span><span class=n>size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>mbe_loss</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=相对绝对误差><a href=#%e7%9b%b8%e5%af%b9%e7%bb%9d%e5%af%b9%e8%af%af%e5%b7%ae class=header-anchor></a>相对绝对误差</h4><p>相对绝对误差（Relative Absolute Error ，RAE）是通过将总绝对误差除以平均值和实际值之间的绝对差来计算的。RAE并以比率表示。RAE的值从0到1。一个好的模型将具有接近于零的值，其中零是最佳值。</p><p>优点：</p><ul><li>RAE 可用于比较以不同单位测量误差的模型。</li><li>RAE 是可靠的，因为它可以防止异常值。</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>relative_absolute_error</span><span class=p>(</span><span class=n>true</span><span class=p>,</span> <span class=n>pred</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>true_mean</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>true</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>squared_error_num</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>true</span> <span class=o>-</span> <span class=n>pred</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>squared_error_den</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>true</span> <span class=o>-</span> <span class=n>true_mean</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>rae_loss</span> <span class=o>=</span> <span class=n>squared_error_num</span> <span class=o>/</span> <span class=n>squared_error_den</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>rae_loss</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=平均绝对百分比误差><a href=#%e5%b9%b3%e5%9d%87%e7%bb%9d%e5%af%b9%e7%99%be%e5%88%86%e6%af%94%e8%af%af%e5%b7%ae class=header-anchor></a>平均绝对百分比误差</h4><p>平均绝对百分比误差(Mean Absolute Percentage Error ,MAPE)是通过将实际值与预测值之间的差值除以实际值来计算的。MAPE 也称为平均绝对百分比偏差，随着误差的增加而线性增加。MAPE 越小，模型性能越好。</p><p>优点：</p><ul><li>MAPE与变量的规模无关，因为它的误差估计是以百分比为单位的。</li><li>所有错误都在一个共同的尺度上标准化，很容易理解。</li><li>MAPE避免了正值和负值相互抵消的问题。</li></ul><p>缺点：</p><ul><li>分母值为零时，面临着“除以零”的问题。</li><li>MAPE对数值较小的误差比对数值大的误差错误的惩罚更多。</li><li>因为使用除法运算，所欲对于相同的误差，实际值的变化将导致损失的差异。</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>mean_absolute_percentage_error</span><span class=p>(</span><span class=n>true</span><span class=p>,</span> <span class=n>pred</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>abs_error</span> <span class=o>=</span> <span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>true</span> <span class=o>-</span> <span class=n>pred</span><span class=p>))</span> <span class=o>/</span> <span class=n>true</span>
</span></span><span class=line><span class=cl>    <span class=n>sum_abs_error</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>abs_error</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>mape_loss</span> <span class=o>=</span> <span class=p>(</span><span class=n>sum_abs_error</span> <span class=o>/</span> <span class=n>true</span><span class=o>.</span><span class=n>size</span><span class=p>)</span> <span class=o>*</span> <span class=mi>100</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>mape_loss</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=均方误差><a href=#%e5%9d%87%e6%96%b9%e8%af%af%e5%b7%ae class=header-anchor></a>均方误差</h4><p>均方误差（Mean Squared Error ，MSE）也称为 L2 损失，MSE通过将预测值和实际值之间的差平方并在整个数据集中对其进行平均来计算误差。MSE 也称为二次损失，因为惩罚与误差不成正比，而是与误差的平方成正比。平方误差为异常值赋予更高的权重，从而为小误差产生平滑的梯度。</p><p>MSE 永远不会是负数，因为误差是平方的。误差值范围从零到无穷大。MSE 随着误差的增加呈指数增长。一个好的模型的 MSE 值接近于零。</p><p>优点：</p><ul><li>MSE会得到一个只有一个全局最小值的梯度下降。</li><li>对于小的误差，它可以有效地收敛到最小值。没有局部最小值。</li><li>MSE 通过对模型进行平方来惩罚具有巨大错误的模型。</li></ul><p>缺点：</p><ul><li>对异常值的敏感性通过对它们进行平方来放大高误差。</li><li>MSE会受到异常值的影响，会寻找在整体水平上表现足够好的模型。</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>mean_squared_error</span><span class=p>(</span><span class=n>true</span><span class=p>,</span> <span class=n>pred</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>squared_error</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>square</span><span class=p>(</span><span class=n>true</span> <span class=o>-</span> <span class=n>pred</span><span class=p>)</span> 
</span></span><span class=line><span class=cl>    <span class=n>sum_squared_error</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>squared_error</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>mse_loss</span> <span class=o>=</span> <span class=n>sum_squared_error</span> <span class=o>/</span> <span class=n>true</span><span class=o>.</span><span class=n>size</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>mse_loss</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=均方根偏差><a href=#%e5%9d%87%e6%96%b9%e6%a0%b9%e5%81%8f%e5%b7%ae class=header-anchor></a>均方根偏差</h4><p>均方根偏差（Root Mean Squared Error ，RMSE）是通过取 MSE 的平方根来计算的。它测量误差的平均幅度，并关注与实际值的偏差。RMSE 值为零表示模型具有完美拟合。RMSE 越低，模型及其预测就越好。</p><p>优点：</p><ul><li>易于理解，计算方便</li></ul><p>缺点：</p><ul><li>建议去除异常值才能使其正常运行。</li><li>会受到数据样本大小的影响。</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>root_mean_squared_error</span><span class=p>(</span><span class=n>true</span><span class=p>,</span> <span class=n>pred</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>squared_error</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>square</span><span class=p>(</span><span class=n>true</span> <span class=o>-</span> <span class=n>pred</span><span class=p>)</span> 
</span></span><span class=line><span class=cl>    <span class=n>sum_squared_error</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>squared_error</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>rmse_loss</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>sum_squared_error</span> <span class=o>/</span> <span class=n>true</span><span class=o>.</span><span class=n>size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>rmse_loss</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=相对平方误差><a href=#%e7%9b%b8%e5%af%b9%e5%b9%b3%e6%96%b9%e8%af%af%e5%b7%ae class=header-anchor></a>相对平方误差</h4><p>相对平方误差(Relative Squared Error ,RSE)需要使用均方误差并将其除以实际数据与数据平均值之间的差异的平方。</p><p>优点</p><ul><li>对预测的平均值和规模不敏感。</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>relative_squared_error</span><span class=p>(</span><span class=n>true</span><span class=p>,</span> <span class=n>pred</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>true_mean</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>true</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>squared_error_num</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>square</span><span class=p>(</span><span class=n>true</span> <span class=o>-</span> <span class=n>pred</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>squared_error_den</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>square</span><span class=p>(</span><span class=n>true</span> <span class=o>-</span> <span class=n>true_mean</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>rse_loss</span> <span class=o>=</span> <span class=n>squared_error_num</span> <span class=o>/</span> <span class=n>squared_error_den</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>rse_loss</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=归一化-rmse><a href=#%e5%bd%92%e4%b8%80%e5%8c%96-rmse class=header-anchor></a>归一化 RMSE</h4><p>归一化 RMSE 通常通过除以一个标量值来计算，它可以有不同的方式。有时选择四分位数范围可能是最好的选择，因为其他方法容易出现异常值。当您想要比较不同因变量的模型或修改因变量时，NRMSE 是一个很好的度量。它克服了尺度依赖性，简化了不同尺度模型甚至数据集之间的比较。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>normalized_root_mean_squared_error</span><span class=p>(</span><span class=n>true</span><span class=p>,</span> <span class=n>pred</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>squared_error</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>square</span><span class=p>((</span><span class=n>true</span> <span class=o>-</span> <span class=n>pred</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>sum_squared_error</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>squared_error</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>rmse</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>sum_squared_error</span> <span class=o>/</span> <span class=n>true</span><span class=o>.</span><span class=n>size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>nrmse_loss</span> <span class=o>=</span> <span class=n>rmse</span><span class=o>/</span><span class=n>np</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=n>pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>nrmse_loss</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=分类性能指标><a href=#%e5%88%86%e7%b1%bb%e6%80%a7%e8%83%bd%e6%8c%87%e6%a0%87 class=header-anchor></a>分类性能指标</h3><h4 id=混淆矩阵><a href=#%e6%b7%b7%e6%b7%86%e7%9f%a9%e9%98%b5 class=header-anchor></a>混淆矩阵</h4><p>​ 也叫可能性矩阵或错误矩阵。混淆矩阵是可视化工具，特别用于监督学习，在无监督学习一般叫做匹配矩阵。在图像精度评价中，主要用于比较分类结果和实际测得值，可以把分类结果的精度显示在一个混淆矩阵里面。</p><div class=table-wrapper><table><thead><tr><th>None</th><th>预测1</th><th>预测0</th><th>合计</th></tr></thead><tbody><tr><td>实际1(P)</td><td>TP</td><td>FN</td><td>TP+FN (P)</td></tr><tr><td>实际0(N)</td><td>FP</td><td>TN</td><td>FP+TN(N)</td></tr><tr><td>合计</td><td>TP+FP</td><td>FN+TN</td><td>TP+FN+FP+TN</td></tr></tbody></table></div><p>其中<strong>T/F表示预测是否正确</strong>，<strong>P/N表示预测的label</strong>而不是实际的label</p><p>True Positive（TP）：真正类。样本的真实类别是正类，并且模型识别的结果也是正类。</p><p>False Negative（FN）：假负类。样本的真实类别是正类，但是模型将其识别为负类。</p><p>False Positive（FP）：假正类。样本的真实类别是负类，但是模型将其识别为正类。</p><p>True Negative（TN）：真负类。样本的真实类别是负类，并且模型将其识别为负类。</p><h4 id=准确率><a href=#%e5%87%86%e7%a1%ae%e7%8e%87 class=header-anchor></a>准确率</h4>$$Acc=(TP+TN)/(TP+FN+FP+TN)$$<p>​ 即预测正确的样本比例，表示了一个分类器的区分能力，注意，这里的区分能力<strong>没有偏向于是正例还是负例</strong>，这也是Accuracy作为性能指标最大的问题所在。</p><ul><li><strong>优点</strong>：简单易懂。</li><li><strong>缺点</strong>：在类别不平衡的情况下，容易产生误导。例如，当正负样本比例极度不平衡时，模型即使预测所有样本为多数类，也可能得到较高的准确率。</li></ul><h4 id=精确率查准率><a href=#%e7%b2%be%e7%a1%ae%e7%8e%87%e6%9f%a5%e5%87%86%e7%8e%87 class=header-anchor></a>精确率/查准率</h4>$$Pre=TP/(TP+FP)$$<p>​ 表示在所有被预测为正例的样本中，真正是正例的比例。对于数据不平衡或是当某一方数据漏掉(通常是把这样的例子作为正例)时会产生很大的代价的时候，我们需要更有效的指标作为补充。</p><ul><li><strong>优点</strong>：在关注预测结果为正类时的正确性（如垃圾邮件检测）时，精确率是一个重要指标。</li><li><strong>缺点</strong>：忽略了实际正类样本中有多少被正确预测。</li></ul><h4 id=召回率查全率敏感度><a href=#%e5%8f%ac%e5%9b%9e%e7%8e%87%e6%9f%a5%e5%85%a8%e7%8e%87%e6%95%8f%e6%84%9f%e5%ba%a6 class=header-anchor></a>召回率/查全率/敏感度</h4>$$Recall=TP/(TP+FN)$$<p>​ 表示在所有实际为正例的样本中，被预测为正例的比例。在医学领域中，常把患病这样的高风险类别作为正类，<strong>当漏掉正类的代价非常高</strong>，像是漏诊可能导致病人的延迟治疗，召回率就很重要。</p><p>在医学中，必须极力<strong>降低漏诊率</strong>，而误诊(把负例判为正例)相对于漏诊的重要性就低了很多。</p><ul><li><strong>优点</strong>：在关注所有正类样本都被正确识别时（如疾病检测），召回率是一个重要指标。</li><li><strong>缺点</strong>：忽略了预测为正类的样本中有多少是错误的。</li></ul><h4 id=特异性><a href=#%e7%89%b9%e5%bc%82%e6%80%a7 class=header-anchor></a>特异性</h4>$$Specificity=TN/(FP+TN)$$<p>​ 表示在所有实际为负的样本中，被预测为负例的比例，即有多大概率被预测出来。可以简单地将特异性理解为负例查全率。特异性在医疗中也被认为是一个重要指标，因为特异性低也就是“误诊率高”，举一个极端例子，一个分类器把所有的样本都判定成患病，此时敏感度为1，但是有特异性却很低。因此，在医学领域，特异性和敏感度是需要同时考量的。</p><ul><li><strong>优点</strong>：关注负类性能，在<strong>负类重要性高</strong>的任务中（如疾病筛查中的健康人判断），特异性比准确率（Accuracy）更能反映模型对负类的识别能力。</li><li><strong>缺点</strong>：忽略正类性能，依赖明确的负类定义，无法单独作为评估标准</li></ul><h4 id=fβ_><a href=#f%ce%b2_ class=header-anchor></a><strong>Fβ_Score</strong></h4><p>​ Fβ的物理意义就是将精确率和召回率的一种加权平均，在合并的过程中，召回率的权重是精确率的β倍。常用的是F1分数（F1 Score），是统计学中用来衡量二分类模型精确度的一种指标。Accuracy和F1-Score是判断分类模型总体的标准。</p><p><img src=https://i-blog.csdnimg.cn/blog_migrate/3e4f2a0cd742ceae4650569c634cfaf2.png loading=lazy alt="F1 score计算"></p><p><img src=https://i-blog.csdnimg.cn/blog_migrate/6c57b65304c7a309b71f5795d6d8ddfb.png loading=lazy alt="Fβ score计算"></p><ul><li><p>Macro-F1和Micro-F1是相对于多标签分类而言的。</p></li><li><p>Micro-F1，计算出<strong>所有类别总的</strong>Precision和Recall，然后计算F1。</p></li><li><p>Macro-F1，计算出<strong>每一个类的</strong>Precison和Recall后计算F1，最后将F1平均。</p><p>​</p></li><li><p><strong>优点</strong>：在类别不平衡的情况下，比单独使用精确率或召回率更能全面反映模型性能。</p></li><li><p><strong>缺点</strong>：无法同时优化精确率和召回率的具体值。</p></li></ul><h4 id=roc曲线和auc><a href=#roc%e6%9b%b2%e7%ba%bf%e5%92%8cauc class=header-anchor></a>ROC曲线和AUC</h4><p>​ ROC曲线的全称叫做Receiver Operating Characteristic，常常被用来判别一个分类器的好坏程度</p><p><img src=https://i-blog.csdnimg.cn/blog_migrate/c030c4ec2fbed37d0093ac0428d796fb.png loading=lazy alt=ROC曲线></p><p>x轴坐标是False positive rate，即假正率，定义为</p>$$FPR=FP/(FP+TN)=1-Specificity$$<p>，即误诊率，代表所有实际为负例的样本中，预测错误的比例。</p><p>y轴坐标是True positive rate，即真正率，定义为</p>$$TPR=TP/(TP+FN)$$<p>,即召回率/查全率/敏感度</p><p>现在可知，ROC的x轴是误诊率，y轴是漏诊率。</p><p>​ AUC，即曲线下面积（Area Under Curve），是 ROC 曲线下面积的一个数值表示。它提供了一个定量的指标，用来衡量分类模型的整体表现。AUC 值范围从 0 到 1，值越大表示模型性能越好。</p><img src=https://i-blog.csdnimg.cn/blog_migrate/e4931f4fe68fc59f133ab07528b12498.png alt=在这里插入图片描述 style=zoom:33%><p>下方是具体绘制的方法</p><p>画出ROC的曲线的方法不只是计算一次误诊率和漏诊率，按照以下方式进行：</p><ol><li>将分类器预测为正例的概率从小到大排序</li><li>把每两个样本间的概率作为阈值，小于该阈值的分为负例，大于的分为正例</li><li>分别计算TPR和FPR</li><li>转2</li><li>当所有阈值都被枚举完之后，获得一组(TPR, FPR)的坐标点，将它们画出来。结束</li></ol><p>下方是具体的python代码</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.metrics</span> <span class=kn>import</span> <span class=n>roc_curve</span>
</span></span><span class=line><span class=cl>    <span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>p_rate</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>get_prob</span><span class=p>(</span><span class=n>X</span><span class=p>)</span> <span class=c1>#计算分类器把样本分为正例的概率</span>
</span></span><span class=line><span class=cl>    <span class=n>fpr</span><span class=p>,</span> <span class=n>tpr</span><span class=p>,</span> <span class=n>thresh</span> <span class=o>=</span> <span class=n>roc_curve</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>p_rate</span><span class=p>)</span>
</span></span><span class=line><span class=cl>   
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>5</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;ROC Curve&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;False Positive Rate&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;True Positive Rate&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>fpr</span><span class=p>,</span> <span class=n>tpr</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>savefig</span><span class=p>(</span><span class=s1>&#39;roc.png&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>​ 模型的ROC曲线<strong>离对角线越近，模型的准确率越低</strong>。如果模型真的很好，随着有序列表（第一张由元组标号的图）向下移动，开始就可能遇到真正例元组，图开始就陡峭地从 0 开始上升，后来遇到的真正例越来越少，假正例越来越多，曲线平缓变得更加水平。</p><p>​ 为了评估模型的准确率，可以测量曲线下方的面积（AUC）。面积越接近 0.5 ，模型的准确率越低。完全正确的模型面积为 1.0</p><ul><li>优点：<ol><li>兼顾正例和负例的权衡。因为TPR聚焦于正例，FPR聚焦于与负例，使其成为一个比较均衡的评估方法。</li><li>ROC曲线选用的两个指标，不受类别不平衡影响，都不依赖于具体的类别分布，全面反映模型在不同阈值下的性能。</li></ol></li><li><strong>缺点</strong>：计算复杂度较高，解释起来可能不直观。</li></ul></section><footer class=article-footer><section class=article-tags><a href=/tags/model-evalution/>Model Evalution</a>
<a href=/tags/metrics/>Metrics</a>
<a href=/tags/machine-learning/>Machine Learning</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under xzxg001</span></section><section class=article-lastmod><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>最后更新于 Apr 04, 2024 00:00 UTC</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/paper/><div class=article-image><img src=/p/paper/image.2ffb3054200bdf1b49fa9cfb40a4548c_hu_1c2e15332121f33a.png width=250 height=150 loading=lazy alt="Featured image of post CLIPSelf" data-key=paper data-hash="md5-L/swVCAL3xtJ+pz7QKRUjA=="></div><div class=article-details><h2 class=article-title>CLIPSelf</h2></div></a></article></div></div></aside><div class=disqus-container><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//hugo-theme-stack.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><style>.disqus-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}</style><script>window.addEventListener("onColorSchemeChange",e=>{typeof DISQUS=="object"&&DISQUS.reset({reload:!0})})</script><footer class=site-footer><section class=copyright>&copy;
2024 -
2025 xzxg001</section><section class=powerby>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>